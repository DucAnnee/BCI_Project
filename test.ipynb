{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb2155a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "from Step_4_MLmodels.PrepareDatasetForLearning import PrepareDatasetForLearning\n",
    "from Step_4_MLmodels.LearningAlgorithms import ClassificationAlgorithms\n",
    "from Step_4_MLmodels.Evaluation import ClassificationEvaluation\n",
    "from Step_4_MLmodels.FeatureSelection import FeatureSelectionClassification\n",
    "from util import util\n",
    "from util.VisualizeDataset import VisualizeDataset\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Set up file names and locations.\n",
    "FOLDER_PATH = Path('C:\\\\Users\\\\DUC_AN\\\\Documents\\\\GitHub\\\\EEG-ICSSE\\\\intermediate_datafiles\\\\motor_imagery\\\\step3_result\\\\all')\n",
    "RESULT_PATH = Path('C:\\\\Users\\\\DUC_AN\\\\Documents\\\\GitHub\\\\EEG-ICSSE\\\\intermediate_datafiles\\\\motor_imagery\\\\step4_result\\\\all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acc2d701",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eba5d345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900-01-01 00:21:15.800    0.0\n",
      "1900-01-01 00:21:17.300    0.0\n",
      "1900-01-01 00:21:18.800    0.0\n",
      "1900-01-01 00:21:20.300    0.0\n",
      "1900-01-01 00:21:21.800    0.0\n",
      "                          ... \n",
      "1900-01-01 00:26:18.800    0.0\n",
      "1900-01-01 00:26:20.300    0.0\n",
      "1900-01-01 00:26:21.800    0.0\n",
      "1900-01-01 00:26:23.300    0.0\n",
      "1900-01-01 00:26:24.800    0.0\n",
      "Length: 207, dtype: float64\n",
      "1900-01-01 00:52:38.000    0.0\n",
      "1900-01-01 00:52:39.500    0.0\n",
      "1900-01-01 00:52:41.000    0.0\n",
      "1900-01-01 00:52:42.500    0.0\n",
      "1900-01-01 00:52:44.000    0.0\n",
      "                          ... \n",
      "1900-01-01 00:57:45.500    0.0\n",
      "1900-01-01 00:57:47.000    0.0\n",
      "1900-01-01 00:57:48.500    0.0\n",
      "1900-01-01 00:57:50.000    0.0\n",
      "1900-01-01 00:57:51.500    0.0\n",
      "Length: 210, dtype: float64\n",
      "1900-01-01 00:03:32.000    0.0\n",
      "1900-01-01 00:03:33.500    0.0\n",
      "1900-01-01 00:03:35.000    0.0\n",
      "1900-01-01 00:03:36.500    0.0\n",
      "1900-01-01 00:03:38.000    0.0\n",
      "                          ... \n",
      "1900-01-01 00:08:41.000    0.0\n",
      "1900-01-01 00:08:42.500    0.0\n",
      "1900-01-01 00:08:44.000    0.0\n",
      "1900-01-01 00:08:45.500    0.0\n",
      "1900-01-01 00:08:47.000    0.0\n",
      "Length: 211, dtype: float64\n",
      "1900-01-01 00:41:40.000    0.0\n",
      "1900-01-01 00:41:41.500    0.0\n",
      "1900-01-01 00:41:43.000    0.0\n",
      "1900-01-01 00:41:44.500    0.0\n",
      "1900-01-01 00:41:46.000    0.0\n",
      "                          ... \n",
      "1900-01-01 00:46:49.000    0.0\n",
      "1900-01-01 00:46:50.500    0.0\n",
      "1900-01-01 00:46:52.000    0.0\n",
      "1900-01-01 00:46:53.500    0.0\n",
      "1900-01-01 00:46:55.000    0.0\n",
      "Length: 211, dtype: float64\n",
      "1900-01-01 00:47:10.300    0.0\n",
      "1900-01-01 00:47:11.800    0.0\n",
      "1900-01-01 00:47:13.300    0.0\n",
      "1900-01-01 00:47:14.800    0.0\n",
      "1900-01-01 00:47:16.300    0.0\n",
      "                          ... \n",
      "1900-01-01 00:52:17.800    0.0\n",
      "1900-01-01 00:52:19.300    0.0\n",
      "1900-01-01 00:52:20.800    0.0\n",
      "1900-01-01 00:52:22.300    0.0\n",
      "1900-01-01 00:52:23.800    0.0\n",
      "Length: 210, dtype: float64\n",
      "1900-01-01 00:23:35.800    0.0\n",
      "1900-01-01 00:23:37.300    0.0\n",
      "1900-01-01 00:23:38.800    0.0\n",
      "1900-01-01 00:23:40.300    0.0\n",
      "1900-01-01 00:23:41.800    0.0\n",
      "                          ... \n",
      "1900-01-01 00:28:46.300    0.0\n",
      "1900-01-01 00:28:47.800    0.0\n",
      "1900-01-01 00:28:49.300    0.0\n",
      "1900-01-01 00:28:50.800    0.0\n",
      "1900-01-01 00:28:52.300    0.0\n",
      "Length: 212, dtype: float64\n",
      "1900-01-01 00:30:11.400    0.0\n",
      "1900-01-01 00:30:12.900    0.0\n",
      "1900-01-01 00:30:14.400    0.0\n",
      "1900-01-01 00:30:15.900    0.0\n",
      "1900-01-01 00:30:17.400    0.0\n",
      "                          ... \n",
      "1900-01-01 00:35:23.400    0.0\n",
      "1900-01-01 00:35:24.900    0.0\n",
      "1900-01-01 00:35:26.400    0.0\n",
      "1900-01-01 00:35:27.900    0.0\n",
      "1900-01-01 00:35:29.400    0.0\n",
      "Length: 213, dtype: float64\n",
      "1900-01-01 00:36:02.300    0.0\n",
      "1900-01-01 00:36:03.800    0.0\n",
      "1900-01-01 00:36:05.300    0.0\n",
      "1900-01-01 00:36:06.800    0.0\n",
      "1900-01-01 00:36:08.300    0.0\n",
      "                          ... \n",
      "1900-01-01 00:41:09.800    0.0\n",
      "1900-01-01 00:41:11.300    0.0\n",
      "1900-01-01 00:41:12.800    0.0\n",
      "1900-01-01 00:41:14.300    0.0\n",
      "1900-01-01 00:41:15.800    0.0\n",
      "Length: 210, dtype: float64\n",
      "1900-01-01 00:07:14.900    0.0\n",
      "1900-01-01 00:07:16.400    0.0\n",
      "1900-01-01 00:07:17.900    0.0\n",
      "1900-01-01 00:07:19.400    0.0\n",
      "1900-01-01 00:07:20.900    0.0\n",
      "                          ... \n",
      "1900-01-01 00:12:22.400    0.0\n",
      "1900-01-01 00:12:23.900    0.0\n",
      "1900-01-01 00:12:25.400    0.0\n",
      "1900-01-01 00:12:26.900    0.0\n",
      "1900-01-01 00:12:28.400    0.0\n",
      "Length: 210, dtype: float64\n",
      "1900-01-01 00:12:40.300    0.0\n",
      "1900-01-01 00:12:41.800    0.0\n",
      "1900-01-01 00:12:43.300    0.0\n",
      "1900-01-01 00:12:44.800    0.0\n",
      "1900-01-01 00:12:46.300    0.0\n",
      "                          ... \n",
      "1900-01-01 00:17:44.800    0.0\n",
      "1900-01-01 00:17:46.300    0.0\n",
      "1900-01-01 00:17:47.800    0.0\n",
      "1900-01-01 00:17:49.300    0.0\n",
      "1900-01-01 00:17:50.800    0.0\n",
      "Length: 208, dtype: float64\n",
      "1900-01-01 00:47:10.300    0.0\n",
      "1900-01-01 00:47:11.800    0.0\n",
      "1900-01-01 00:47:13.300    0.0\n",
      "1900-01-01 00:47:14.800    0.0\n",
      "1900-01-01 00:47:16.300    0.0\n",
      "                          ... \n",
      "1900-01-01 00:52:17.800    0.0\n",
      "1900-01-01 00:52:19.300    0.0\n",
      "1900-01-01 00:52:20.800    0.0\n",
      "1900-01-01 00:52:22.300    0.0\n",
      "1900-01-01 00:52:23.800    0.0\n",
      "Length: 210, dtype: float64\n",
      "1900-01-01 00:52:38.000    0.0\n",
      "1900-01-01 00:52:39.500    0.0\n",
      "1900-01-01 00:52:41.000    0.0\n",
      "1900-01-01 00:52:42.500    0.0\n",
      "1900-01-01 00:52:44.000    0.0\n",
      "                          ... \n",
      "1900-01-01 00:57:45.500    0.0\n",
      "1900-01-01 00:57:47.000    0.0\n",
      "1900-01-01 00:57:48.500    0.0\n",
      "1900-01-01 00:57:50.000    0.0\n",
      "1900-01-01 00:57:51.500    0.0\n",
      "Length: 210, dtype: float64\n",
      "1900-01-01 00:03:32.000    0.0\n",
      "1900-01-01 00:03:33.500    0.0\n",
      "1900-01-01 00:03:35.000    0.0\n",
      "1900-01-01 00:03:36.500    0.0\n",
      "1900-01-01 00:03:38.000    0.0\n",
      "                          ... \n",
      "1900-01-01 00:08:41.000    0.0\n",
      "1900-01-01 00:08:42.500    0.0\n",
      "1900-01-01 00:08:44.000    0.0\n",
      "1900-01-01 00:08:45.500    0.0\n",
      "1900-01-01 00:08:47.000    0.0\n",
      "Length: 211, dtype: float64\n",
      "1900-01-01 00:50:29.400    0.0\n",
      "1900-01-01 00:50:30.900    0.0\n",
      "1900-01-01 00:50:32.400    0.0\n",
      "1900-01-01 00:50:33.900    0.0\n",
      "1900-01-01 00:50:35.400    0.0\n",
      "                          ... \n",
      "1900-01-01 00:56:00.900    0.0\n",
      "1900-01-01 00:56:02.400    0.0\n",
      "1900-01-01 00:56:03.900    0.0\n",
      "1900-01-01 00:56:05.400    0.0\n",
      "1900-01-01 00:56:06.900    0.0\n",
      "Length: 226, dtype: float64\n",
      "1900-01-01 00:46:00.200    0.0\n",
      "1900-01-01 00:46:01.700    0.0\n",
      "1900-01-01 00:46:03.200    0.0\n",
      "1900-01-01 00:46:04.700    0.0\n",
      "1900-01-01 00:46:06.200    0.0\n",
      "                          ... \n",
      "1900-01-01 00:49:58.700    0.0\n",
      "1900-01-01 00:50:00.200    0.0\n",
      "1900-01-01 00:50:01.700    0.0\n",
      "1900-01-01 00:50:03.200    0.0\n",
      "1900-01-01 00:50:04.700    0.0\n",
      "Length: 164, dtype: float64\n",
      "1900-01-01 00:39:41.100    0.0\n",
      "1900-01-01 00:39:42.600    0.0\n",
      "1900-01-01 00:39:44.100    0.0\n",
      "1900-01-01 00:39:45.600    0.0\n",
      "1900-01-01 00:39:47.100    0.0\n",
      "                          ... \n",
      "1900-01-01 00:45:30.600    0.0\n",
      "1900-01-01 00:45:32.100    0.0\n",
      "1900-01-01 00:45:33.600    0.0\n",
      "1900-01-01 00:45:35.100    0.0\n",
      "1900-01-01 00:45:36.600    0.0\n",
      "Length: 238, dtype: float64\n",
      "1900-01-01 00:16:29.300    0.0\n",
      "1900-01-01 00:16:30.800    0.0\n",
      "1900-01-01 00:16:32.300    0.0\n",
      "1900-01-01 00:16:33.800    0.0\n",
      "1900-01-01 00:16:35.300    0.0\n",
      "                          ... \n",
      "1900-01-01 00:21:51.800    0.0\n",
      "1900-01-01 00:21:53.300    0.0\n",
      "1900-01-01 00:21:54.800    0.0\n",
      "1900-01-01 00:21:56.300    0.0\n",
      "1900-01-01 00:21:57.800    0.0\n",
      "Length: 220, dtype: float64\n",
      "1900-01-01 00:16:29.300    0.0\n",
      "1900-01-01 00:16:30.800    0.0\n",
      "1900-01-01 00:16:32.300    0.0\n",
      "1900-01-01 00:16:33.800    0.0\n",
      "1900-01-01 00:16:35.300    0.0\n",
      "                          ... \n",
      "1900-01-01 00:21:51.800    0.0\n",
      "1900-01-01 00:21:53.300    0.0\n",
      "1900-01-01 00:21:54.800    0.0\n",
      "1900-01-01 00:21:56.300    0.0\n",
      "1900-01-01 00:21:57.800    0.0\n",
      "Length: 220, dtype: float64\n",
      "1900-01-01 00:10:44.500    0.0\n",
      "1900-01-01 00:10:46.000    0.0\n",
      "1900-01-01 00:10:47.500    0.0\n",
      "1900-01-01 00:10:49.000    0.0\n",
      "1900-01-01 00:10:50.500    0.0\n",
      "                          ... \n",
      "1900-01-01 00:16:02.500    0.0\n",
      "1900-01-01 00:16:04.000    0.0\n",
      "1900-01-01 00:16:05.500    0.0\n",
      "1900-01-01 00:16:07.000    0.0\n",
      "1900-01-01 00:16:08.500    0.0\n",
      "Length: 217, dtype: float64\n",
      "1900-01-01 00:05:17.500    0.0\n",
      "1900-01-01 00:05:19.000    0.0\n",
      "1900-01-01 00:05:20.500    0.0\n",
      "1900-01-01 00:05:22.000    0.0\n",
      "1900-01-01 00:05:23.500    0.0\n",
      "                          ... \n",
      "1900-01-01 00:10:11.500    0.0\n",
      "1900-01-01 00:10:13.000    0.0\n",
      "1900-01-01 00:10:14.500    0.0\n",
      "1900-01-01 00:10:16.000    0.0\n",
      "1900-01-01 00:10:17.500    0.0\n",
      "Length: 201, dtype: float64\n",
      "1900-01-01 00:11:30.900    0.0\n",
      "1900-01-01 00:11:32.400    0.0\n",
      "1900-01-01 00:11:33.900    0.0\n",
      "1900-01-01 00:11:35.400    0.0\n",
      "1900-01-01 00:11:36.900    0.0\n",
      "                          ... \n",
      "1900-01-01 00:16:39.900    0.0\n",
      "1900-01-01 00:16:41.400    0.0\n",
      "1900-01-01 00:16:42.900    0.0\n",
      "1900-01-01 00:16:44.400    0.0\n",
      "1900-01-01 00:16:45.900    0.0\n",
      "Length: 211, dtype: float64\n",
      "1900-01-01 00:04:49.400    0.0\n",
      "1900-01-01 00:04:50.900    0.0\n",
      "1900-01-01 00:04:52.400    0.0\n",
      "1900-01-01 00:04:53.900    0.0\n",
      "1900-01-01 00:04:55.400    0.0\n",
      "                          ... \n",
      "1900-01-01 00:09:41.900    0.0\n",
      "1900-01-01 00:09:43.400    0.0\n",
      "1900-01-01 00:09:44.900    0.0\n",
      "1900-01-01 00:09:46.400    0.0\n",
      "1900-01-01 00:09:47.900    0.0\n",
      "Length: 200, dtype: float64\n",
      "1900-01-01 00:11:55.400    0.0\n",
      "1900-01-01 00:11:56.900    0.0\n",
      "1900-01-01 00:11:58.400    0.0\n",
      "1900-01-01 00:11:59.900    0.0\n",
      "1900-01-01 00:12:01.400    0.0\n",
      "                          ... \n",
      "1900-01-01 00:17:17.900    0.0\n",
      "1900-01-01 00:17:19.400    0.0\n",
      "1900-01-01 00:17:20.900    0.0\n",
      "1900-01-01 00:17:22.400    0.0\n",
      "1900-01-01 00:17:23.900    0.0\n",
      "Length: 220, dtype: float64\n",
      "1900-01-01 00:17:39.100    0.0\n",
      "1900-01-01 00:17:40.600    0.0\n",
      "1900-01-01 00:17:42.100    0.0\n",
      "1900-01-01 00:17:43.600    0.0\n",
      "1900-01-01 00:17:45.100    0.0\n",
      "                          ... \n",
      "1900-01-01 00:23:19.600    0.0\n",
      "1900-01-01 00:23:21.100    0.0\n",
      "1900-01-01 00:23:22.600    0.0\n",
      "1900-01-01 00:23:24.100    0.0\n",
      "1900-01-01 00:23:25.600    0.0\n",
      "Length: 232, dtype: float64\n",
      "1900-01-01 00:23:37.700    0.0\n",
      "1900-01-01 00:23:39.200    0.0\n",
      "1900-01-01 00:23:40.700    0.0\n",
      "1900-01-01 00:23:42.200    0.0\n",
      "1900-01-01 00:23:43.700    0.0\n",
      "                          ... \n",
      "1900-01-01 00:27:27.200    0.0\n",
      "1900-01-01 00:27:28.700    0.0\n",
      "1900-01-01 00:27:30.200    0.0\n",
      "1900-01-01 00:27:31.700    0.0\n",
      "1900-01-01 00:27:33.200    0.0\n",
      "Length: 158, dtype: float64\n",
      "Training set length is:  3132\n",
      "Validation set length is:  1051\n",
      "Test set length is:  1057\n"
     ]
    }
   ],
   "source": [
    "RESULT_PATH.mkdir(exist_ok=True, parents=True)\n",
    "# for this script, we want to first load in all datasets\n",
    "# since the Prepare dataset function accepts a list of pd dataframes\n",
    "prepare = PrepareDatasetForLearning()\n",
    "all_datasets = []\n",
    "\n",
    "for instance in os.scandir(FOLDER_PATH): # go through all instances of experiments\n",
    "    instance_path = instance.path\n",
    "    dataset = pd.read_csv(instance_path, index_col=0)\n",
    "    dataset.index = pd.to_datetime(dataset.index)\n",
    "    all_datasets.append(dataset)\n",
    "\n",
    "#now all dataframes are added to the list all_datasets\n",
    "#print(all_datasets)\n",
    "\n",
    "# Let's create our visualization class again.\n",
    "\n",
    "'''\n",
    "the classification of the motor imagery can be seen as a non-temporal task, as we want to predict imagery based on a window of e.g. 2 sec,\n",
    "without taking into account previous windows.\n",
    "We first create 1 column representing our classes, and then create a train val test split of 60 20 20\n",
    "In order to do this, we first create a train test split of 80 20, and then for the train set we split again in 75 25\n",
    "For each dataset instance. we split trainvaltest split individually.\n",
    "Then later we add all train data together, all val data together, and all test data together.\n",
    "This way we sample randomly across all users to get a result for the whole 'population' of subjects.\n",
    "'''\n",
    "# we set filter is false so also the data besides left and right are taken with us\n",
    "train_X, val_X, test_X, train_y, val_y, test_y = prepare.split_multiple_datasets_classification(\n",
    "    all_datasets, ['0', '1'], 'like', [0.2, 0.25],filter=False, temporal=False)\n",
    "print('Training set length is: ', len(train_X.index))\n",
    "print('Validation set length is: ', len(val_X.index))\n",
    "print('Test set length is: ', len(test_X.index))   \n",
    "\n",
    "# select subsets of features which we will consider:\n",
    "pca_features = ['pca_1','pca_2','pca_3','pca_4']\n",
    "ica_features = ['FastICA_1','FastICA_2','FastICA_3','FastICA_4','FastICA_5','FastICA_6','FastICA_7','FastICA_8','FastICA_9','FastICA_10',\n",
    "'FastICA_11','FastICA_12','FastICA_13','FastICA_14','FastICA_15','FastICA_16','FastICA_17','FastICA_18','FastICA_19','FastICA_20']\n",
    "time_features = [name for name in dataset.columns if '_temp_' in name]\n",
    "freq_features = [name for name in dataset.columns if (('_freq' in name) or ('_pse' in name))]\n",
    "\n",
    "\n",
    "# feature selection below we will use as input for our models:\n",
    "basic_features = ['Delta_TP9','Delta_AF7','Delta_AF8','Delta_TP10','Theta_TP9','Theta_AF7','Theta_AF8','Theta_TP10','Alpha_TP9','Alpha_AF7',\n",
    "'Alpha_AF8','Alpha_TP10','Beta_TP9','Beta_AF7','Beta_AF8','Beta_TP10','Gamma_TP9','Gamma_AF7','Gamma_AF8','Gamma_TP10']\n",
    "basic_w_PCA = list(set().union(basic_features, pca_features))\n",
    "basic_w_ICA = list(set().union(basic_features, ica_features))\n",
    "all_features = list(set().union(basic_features, ica_features, time_features, freq_features))\n",
    "\n",
    "fs = FeatureSelectionClassification()\n",
    "num_features = 20\n",
    "\n",
    "# we will select the top 20 features based on an experiment with a deciscion tree which we will use as input for our models as well\n",
    "# this is already been run, see below\n",
    "\n",
    "'''\n",
    "selected_features, ordered_features, ordered_scores = fs.forward_selection(num_features,\n",
    "                                                              train_X[all_features],\n",
    "                                                              test_X[all_features],\n",
    "                                                              train_y,\n",
    "                                                              test_y,\n",
    "                                                              gridsearch=False)\n",
    "print(selected_features)\n",
    "'''\n",
    "\n",
    "# the best feature are right now:\n",
    "selected_features = ['Delta_AF7_temp_max_ws_10', 'Alpha_TP9_temp_mean_ws_10', 'Delta_AF7_temp_slope_ws_30', 'FastICA_2', \n",
    "'Alpha_TP9_temp_median_ws_20', 'Delta_AF8_temp_max_ws_10', 'Beta_TP10_freq_30.0_Hz_ws_10', \n",
    "'Beta_TP9_temp_std_ws_20', 'Theta_TP10_temp_max_ws_20', 'Gamma_TP9_temp_median_ws_20',\n",
    " 'Gamma_TP10_freq_30.0_Hz_ws_10', 'Alpha_TP10_temp_std_ws_20', 'Gamma_AF7_freq_30.0_Hz_ws_10', 'Delta_TP10', \n",
    " 'Beta_TP9_temp_median_ws_20', 'Delta_TP10_temp_min_ws_20', 'Theta_TP9_temp_median_ws_30', \n",
    " 'Delta_AF8_temp_min_ws_20', 'Delta_AF8_temp_mean_ws_10', 'Beta_TP9_freq_0.0_Hz_ws_10']\n",
    "\n",
    "\n",
    "possible_feature_sets = [basic_features, basic_w_PCA, basic_w_ICA, all_features, selected_features]\n",
    "feature_names = ['initial set', 'basic_w_PCA', 'basic_w_ICA', 'all_features', 'Selected features']\n",
    "N_KCV_REPEATS = 10 # some non deterministic models we will run a couple of times as their inits are random to get average results\n",
    "\n",
    "\n",
    "# then here, we run each model\n",
    "learner = ClassificationAlgorithms()\n",
    "eval = ClassificationEvaluation()\n",
    "scores_over_all_algs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eab46a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "check    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d2abbd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900-01-01 00:27:16.700000</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900-01-01 00:25:19.700000</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900-01-01 00:24:57.200000</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900-01-01 00:27:31.700000</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900-01-01 00:25:58.700000</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3132 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            check\n",
       "0                             1.0\n",
       "1                             1.0\n",
       "2                             1.0\n",
       "3                             1.0\n",
       "4                             1.0\n",
       "...                           ...\n",
       "1900-01-01 00:27:16.700000    0.0\n",
       "1900-01-01 00:25:19.700000    0.0\n",
       "1900-01-01 00:24:57.200000    0.0\n",
       "1900-01-01 00:27:31.700000    0.0\n",
       "1900-01-01 00:25:58.700000    0.0\n",
       "\n",
       "[3132 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32b6de09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3132\n"
     ]
    }
   ],
   "source": [
    "print(len(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7944370c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a random forest approach for classification upon the training data (with the specified value for\n",
    "# the minimum samples in the leaf, the number of trees, and if we should print some of the details of the\n",
    "# model print_model_details=True) and use the created model to predict the outcome for both the\n",
    "# test and training set. It returns the categorical predictions for the training and test set as well as the\n",
    "# probabilities associated with each class, each class being represented as a column in the data frame.\n",
    "def random_forest(train_X, train_y, test_X, n_estimators=10, min_samples_leaf=5, criterion='gini', print_model_details=False, gridsearch=True, save_model=False):\n",
    "\n",
    "    if gridsearch:\n",
    "        tuned_parameters = [{'min_samples_leaf': [2, 10, 50, 100, 200],\n",
    "                                'n_estimators':[10, 50, 100],\n",
    "                                'criterion':['gini', 'entropy']}]\n",
    "        rf = GridSearchCV(RandomForestClassifier(), tuned_parameters, cv=5, scoring='accuracy', error_score= 'raise')\n",
    "    else:\n",
    "        rf = RandomForestClassifier(n_estimators=n_estimators, min_samples_leaf=min_samples_leaf, criterion=criterion)\n",
    "\n",
    "    # Fit the model\n",
    "\n",
    "    rf.fit(train_X, train_y.check.ravel())\n",
    "\n",
    "    if gridsearch and print_model_details:\n",
    "        print(rf.best_params_)\n",
    "\n",
    "    if gridsearch:\n",
    "        rf = rf.best_estimator_\n",
    "\n",
    "    pred_prob_training_y = rf.predict_proba(train_X)\n",
    "    pred_prob_test_y = rf.predict_proba(test_X)\n",
    "    pred_training_y = rf.predict(train_X)\n",
    "    pred_test_y = rf.predict(test_X)\n",
    "    frame_prob_training_y = pd.DataFrame(pred_prob_training_y, columns=rf.classes_)\n",
    "    frame_prob_test_y = pd.DataFrame(pred_prob_test_y, columns=rf.classes_)\n",
    "\n",
    "    if print_model_details:\n",
    "        ordered_indices = [i[0] for i in sorted(enumerate(rf.feature_importances_), key=lambda x:x[1], reverse=True)]\n",
    "        print('Top 20 feature importances random forest:')\n",
    "        for i in range(0, 20):\n",
    "            print(train_X.columns[ordered_indices[i]], end='')\n",
    "            print(' & ', end='')\n",
    "            print(rf.feature_importances_[ordered_indices[i]])\n",
    "    \n",
    "    if save_model:\n",
    "        # save the model to disk\n",
    "        filename = 'final_' + str(inspect.stack()[0][3]) + '_model_BCI.sav'\n",
    "        pickle.dump(rf, open(filename, 'wb'))\n",
    "\n",
    "    return pred_training_y, pred_test_y, frame_prob_training_y, frame_prob_test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23de2c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.check.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06fcdd67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Delta_TP9                        2266\n",
       "Delta_AF7                        2513\n",
       "Delta_AF8                        2533\n",
       "Delta_TP10                       2210\n",
       "Theta_TP9                        2266\n",
       "                                 ... \n",
       "Gamma_TP10_freq_20.0_Hz_ws_10    1993\n",
       "Gamma_TP10_freq_30.0_Hz_ws_10    1996\n",
       "Gamma_TP10_freq_40.0_Hz_ws_10    1998\n",
       "Gamma_TP10_freq_50.0_Hz_ws_10    2035\n",
       "class                               1\n",
       "Length: 585, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4215abfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Delta_TP9</th>\n",
       "      <th>Delta_AF7</th>\n",
       "      <th>Delta_AF8</th>\n",
       "      <th>Delta_TP10</th>\n",
       "      <th>Theta_TP9</th>\n",
       "      <th>Theta_AF7</th>\n",
       "      <th>Theta_AF8</th>\n",
       "      <th>Theta_TP10</th>\n",
       "      <th>Alpha_TP9</th>\n",
       "      <th>Alpha_AF7</th>\n",
       "      <th>...</th>\n",
       "      <th>Gamma_TP10_max_freq_ws_10</th>\n",
       "      <th>Gamma_TP10_freq_weighted_ws_10</th>\n",
       "      <th>Gamma_TP10_pse_ws_10</th>\n",
       "      <th>Gamma_TP10_freq_0.0_Hz_ws_10</th>\n",
       "      <th>Gamma_TP10_freq_10.0_Hz_ws_10</th>\n",
       "      <th>Gamma_TP10_freq_20.0_Hz_ws_10</th>\n",
       "      <th>Gamma_TP10_freq_30.0_Hz_ws_10</th>\n",
       "      <th>Gamma_TP10_freq_40.0_Hz_ws_10</th>\n",
       "      <th>Gamma_TP10_freq_50.0_Hz_ws_10</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.624402</td>\n",
       "      <td>0.717011</td>\n",
       "      <td>0.919645</td>\n",
       "      <td>0.825707</td>\n",
       "      <td>0.434732</td>\n",
       "      <td>0.115024</td>\n",
       "      <td>0.410620</td>\n",
       "      <td>0.720329</td>\n",
       "      <td>0.648855</td>\n",
       "      <td>-0.082225</td>\n",
       "      <td>...</td>\n",
       "      <td>3.906546e-01</td>\n",
       "      <td>-9.518690e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.471205</td>\n",
       "      <td>-1.672656e-01</td>\n",
       "      <td>-3.406519e-02</td>\n",
       "      <td>-1.800379e-02</td>\n",
       "      <td>9.280505e-03</td>\n",
       "      <td>6.223235e-04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.587482</td>\n",
       "      <td>0.788116</td>\n",
       "      <td>0.932912</td>\n",
       "      <td>0.532051</td>\n",
       "      <td>0.385909</td>\n",
       "      <td>0.638301</td>\n",
       "      <td>0.883139</td>\n",
       "      <td>0.409161</td>\n",
       "      <td>0.734609</td>\n",
       "      <td>0.610241</td>\n",
       "      <td>...</td>\n",
       "      <td>4.598610e-02</td>\n",
       "      <td>3.279093e+00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-0.943916</td>\n",
       "      <td>-6.489695e-02</td>\n",
       "      <td>1.018178e-03</td>\n",
       "      <td>-2.257550e-02</td>\n",
       "      <td>-2.366062e-02</td>\n",
       "      <td>-2.576942e-02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.123026</td>\n",
       "      <td>0.859138</td>\n",
       "      <td>0.532642</td>\n",
       "      <td>1.219550</td>\n",
       "      <td>1.124511</td>\n",
       "      <td>0.327637</td>\n",
       "      <td>0.032039</td>\n",
       "      <td>1.094191</td>\n",
       "      <td>1.066517</td>\n",
       "      <td>0.389382</td>\n",
       "      <td>...</td>\n",
       "      <td>4.251746e-01</td>\n",
       "      <td>-5.265867e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.761696</td>\n",
       "      <td>-1.292887e-01</td>\n",
       "      <td>-1.470459e-01</td>\n",
       "      <td>-7.400607e-02</td>\n",
       "      <td>-5.530642e-02</td>\n",
       "      <td>-9.821715e-02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.657415</td>\n",
       "      <td>0.306352</td>\n",
       "      <td>0.768359</td>\n",
       "      <td>0.516933</td>\n",
       "      <td>0.541668</td>\n",
       "      <td>0.247029</td>\n",
       "      <td>0.336359</td>\n",
       "      <td>0.418441</td>\n",
       "      <td>0.552087</td>\n",
       "      <td>0.595063</td>\n",
       "      <td>...</td>\n",
       "      <td>1.565297e+00</td>\n",
       "      <td>4.080327e+01</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-0.020256</td>\n",
       "      <td>-1.825677e-02</td>\n",
       "      <td>5.910165e-02</td>\n",
       "      <td>5.320403e-02</td>\n",
       "      <td>5.021667e-02</td>\n",
       "      <td>4.955530e-02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.552601</td>\n",
       "      <td>0.338759</td>\n",
       "      <td>0.641789</td>\n",
       "      <td>0.529005</td>\n",
       "      <td>0.139140</td>\n",
       "      <td>-0.474317</td>\n",
       "      <td>-0.358568</td>\n",
       "      <td>0.081230</td>\n",
       "      <td>0.636873</td>\n",
       "      <td>0.053596</td>\n",
       "      <td>...</td>\n",
       "      <td>5.814059e-01</td>\n",
       "      <td>1.406718e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.443273</td>\n",
       "      <td>6.152076e-02</td>\n",
       "      <td>7.756041e-02</td>\n",
       "      <td>8.382619e-02</td>\n",
       "      <td>7.957028e-02</td>\n",
       "      <td>7.309734e-02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900-01-01 00:27:16.700000</th>\n",
       "      <td>1.630634</td>\n",
       "      <td>0.849937</td>\n",
       "      <td>0.805977</td>\n",
       "      <td>1.186253</td>\n",
       "      <td>1.031788</td>\n",
       "      <td>0.672794</td>\n",
       "      <td>0.377008</td>\n",
       "      <td>0.837470</td>\n",
       "      <td>0.848964</td>\n",
       "      <td>0.405224</td>\n",
       "      <td>...</td>\n",
       "      <td>6.735395e-03</td>\n",
       "      <td>1.636710e+00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.950003</td>\n",
       "      <td>-2.344050e-02</td>\n",
       "      <td>-2.312702e-02</td>\n",
       "      <td>-2.271643e-02</td>\n",
       "      <td>-2.233911e-02</td>\n",
       "      <td>-2.211485e-02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900-01-01 00:25:19.700000</th>\n",
       "      <td>0.585597</td>\n",
       "      <td>1.287282</td>\n",
       "      <td>0.756415</td>\n",
       "      <td>0.601682</td>\n",
       "      <td>0.201669</td>\n",
       "      <td>0.867307</td>\n",
       "      <td>0.608366</td>\n",
       "      <td>-0.054366</td>\n",
       "      <td>0.231963</td>\n",
       "      <td>0.907556</td>\n",
       "      <td>...</td>\n",
       "      <td>2.571454e-31</td>\n",
       "      <td>3.801630e-15</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-0.985630</td>\n",
       "      <td>-2.775558e-17</td>\n",
       "      <td>-2.775558e-17</td>\n",
       "      <td>-1.387779e-17</td>\n",
       "      <td>-2.775558e-17</td>\n",
       "      <td>-2.775558e-17</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900-01-01 00:24:57.200000</th>\n",
       "      <td>0.695946</td>\n",
       "      <td>0.501303</td>\n",
       "      <td>0.603439</td>\n",
       "      <td>0.785471</td>\n",
       "      <td>0.582576</td>\n",
       "      <td>0.194988</td>\n",
       "      <td>0.082204</td>\n",
       "      <td>0.215667</td>\n",
       "      <td>0.575390</td>\n",
       "      <td>0.397730</td>\n",
       "      <td>...</td>\n",
       "      <td>1.900079e-02</td>\n",
       "      <td>9.915513e-01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.441876</td>\n",
       "      <td>6.128236e-02</td>\n",
       "      <td>2.742406e-03</td>\n",
       "      <td>-3.178164e-02</td>\n",
       "      <td>-1.113937e-02</td>\n",
       "      <td>-1.382244e-02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900-01-01 00:27:31.700000</th>\n",
       "      <td>0.356150</td>\n",
       "      <td>1.398758</td>\n",
       "      <td>0.836575</td>\n",
       "      <td>0.697885</td>\n",
       "      <td>0.084191</td>\n",
       "      <td>0.912771</td>\n",
       "      <td>0.448495</td>\n",
       "      <td>0.090896</td>\n",
       "      <td>-0.172347</td>\n",
       "      <td>0.780142</td>\n",
       "      <td>...</td>\n",
       "      <td>5.307279e-31</td>\n",
       "      <td>-4.278889e-15</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-0.851370</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>5.551115e-17</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>1.387779e-17</td>\n",
       "      <td>1.734723e-17</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900-01-01 00:25:58.700000</th>\n",
       "      <td>1.113273</td>\n",
       "      <td>1.391481</td>\n",
       "      <td>1.009811</td>\n",
       "      <td>1.120967</td>\n",
       "      <td>0.597128</td>\n",
       "      <td>0.755522</td>\n",
       "      <td>0.564978</td>\n",
       "      <td>0.751203</td>\n",
       "      <td>0.791324</td>\n",
       "      <td>0.729783</td>\n",
       "      <td>...</td>\n",
       "      <td>1.088519e-01</td>\n",
       "      <td>4.315332e+00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-0.942126</td>\n",
       "      <td>1.561232e-02</td>\n",
       "      <td>8.616744e-02</td>\n",
       "      <td>-3.145519e-02</td>\n",
       "      <td>-6.522804e-02</td>\n",
       "      <td>-5.188372e-02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3132 rows × 585 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Delta_TP9  Delta_AF7  Delta_AF8  Delta_TP10   \n",
       "0                            0.624402   0.717011   0.919645    0.825707  \\\n",
       "1                            0.587482   0.788116   0.932912    0.532051   \n",
       "2                            1.123026   0.859138   0.532642    1.219550   \n",
       "3                            0.657415   0.306352   0.768359    0.516933   \n",
       "4                            0.552601   0.338759   0.641789    0.529005   \n",
       "...                               ...        ...        ...         ...   \n",
       "1900-01-01 00:27:16.700000   1.630634   0.849937   0.805977    1.186253   \n",
       "1900-01-01 00:25:19.700000   0.585597   1.287282   0.756415    0.601682   \n",
       "1900-01-01 00:24:57.200000   0.695946   0.501303   0.603439    0.785471   \n",
       "1900-01-01 00:27:31.700000   0.356150   1.398758   0.836575    0.697885   \n",
       "1900-01-01 00:25:58.700000   1.113273   1.391481   1.009811    1.120967   \n",
       "\n",
       "                            Theta_TP9  Theta_AF7  Theta_AF8  Theta_TP10   \n",
       "0                            0.434732   0.115024   0.410620    0.720329  \\\n",
       "1                            0.385909   0.638301   0.883139    0.409161   \n",
       "2                            1.124511   0.327637   0.032039    1.094191   \n",
       "3                            0.541668   0.247029   0.336359    0.418441   \n",
       "4                            0.139140  -0.474317  -0.358568    0.081230   \n",
       "...                               ...        ...        ...         ...   \n",
       "1900-01-01 00:27:16.700000   1.031788   0.672794   0.377008    0.837470   \n",
       "1900-01-01 00:25:19.700000   0.201669   0.867307   0.608366   -0.054366   \n",
       "1900-01-01 00:24:57.200000   0.582576   0.194988   0.082204    0.215667   \n",
       "1900-01-01 00:27:31.700000   0.084191   0.912771   0.448495    0.090896   \n",
       "1900-01-01 00:25:58.700000   0.597128   0.755522   0.564978    0.751203   \n",
       "\n",
       "                            Alpha_TP9  Alpha_AF7  ...   \n",
       "0                            0.648855  -0.082225  ...  \\\n",
       "1                            0.734609   0.610241  ...   \n",
       "2                            1.066517   0.389382  ...   \n",
       "3                            0.552087   0.595063  ...   \n",
       "4                            0.636873   0.053596  ...   \n",
       "...                               ...        ...  ...   \n",
       "1900-01-01 00:27:16.700000   0.848964   0.405224  ...   \n",
       "1900-01-01 00:25:19.700000   0.231963   0.907556  ...   \n",
       "1900-01-01 00:24:57.200000   0.575390   0.397730  ...   \n",
       "1900-01-01 00:27:31.700000  -0.172347   0.780142  ...   \n",
       "1900-01-01 00:25:58.700000   0.791324   0.729783  ...   \n",
       "\n",
       "                            Gamma_TP10_max_freq_ws_10   \n",
       "0                                        3.906546e-01  \\\n",
       "1                                        4.598610e-02   \n",
       "2                                        4.251746e-01   \n",
       "3                                        1.565297e+00   \n",
       "4                                        5.814059e-01   \n",
       "...                                               ...   \n",
       "1900-01-01 00:27:16.700000               6.735395e-03   \n",
       "1900-01-01 00:25:19.700000               2.571454e-31   \n",
       "1900-01-01 00:24:57.200000               1.900079e-02   \n",
       "1900-01-01 00:27:31.700000               5.307279e-31   \n",
       "1900-01-01 00:25:58.700000               1.088519e-01   \n",
       "\n",
       "                            Gamma_TP10_freq_weighted_ws_10   \n",
       "0                                            -9.518690e+00  \\\n",
       "1                                             3.279093e+00   \n",
       "2                                            -5.265867e+01   \n",
       "3                                             4.080327e+01   \n",
       "4                                             1.406718e+01   \n",
       "...                                                    ...   \n",
       "1900-01-01 00:27:16.700000                    1.636710e+00   \n",
       "1900-01-01 00:25:19.700000                    3.801630e-15   \n",
       "1900-01-01 00:24:57.200000                    9.915513e-01   \n",
       "1900-01-01 00:27:31.700000                   -4.278889e-15   \n",
       "1900-01-01 00:25:58.700000                    4.315332e+00   \n",
       "\n",
       "                            Gamma_TP10_pse_ws_10   \n",
       "0                                            0.0  \\\n",
       "1                                           20.0   \n",
       "2                                            0.0   \n",
       "3                                           20.0   \n",
       "4                                            0.0   \n",
       "...                                          ...   \n",
       "1900-01-01 00:27:16.700000                  50.0   \n",
       "1900-01-01 00:25:19.700000                  30.0   \n",
       "1900-01-01 00:24:57.200000                  10.0   \n",
       "1900-01-01 00:27:31.700000                  20.0   \n",
       "1900-01-01 00:25:58.700000                  20.0   \n",
       "\n",
       "                            Gamma_TP10_freq_0.0_Hz_ws_10   \n",
       "0                                               0.471205  \\\n",
       "1                                              -0.943916   \n",
       "2                                               0.761696   \n",
       "3                                              -0.020256   \n",
       "4                                               0.443273   \n",
       "...                                                  ...   \n",
       "1900-01-01 00:27:16.700000                     -1.950003   \n",
       "1900-01-01 00:25:19.700000                     -0.985630   \n",
       "1900-01-01 00:24:57.200000                     -1.441876   \n",
       "1900-01-01 00:27:31.700000                     -0.851370   \n",
       "1900-01-01 00:25:58.700000                     -0.942126   \n",
       "\n",
       "                            Gamma_TP10_freq_10.0_Hz_ws_10   \n",
       "0                                           -1.672656e-01  \\\n",
       "1                                           -6.489695e-02   \n",
       "2                                           -1.292887e-01   \n",
       "3                                           -1.825677e-02   \n",
       "4                                            6.152076e-02   \n",
       "...                                                   ...   \n",
       "1900-01-01 00:27:16.700000                  -2.344050e-02   \n",
       "1900-01-01 00:25:19.700000                  -2.775558e-17   \n",
       "1900-01-01 00:24:57.200000                   6.128236e-02   \n",
       "1900-01-01 00:27:31.700000                   2.775558e-17   \n",
       "1900-01-01 00:25:58.700000                   1.561232e-02   \n",
       "\n",
       "                            Gamma_TP10_freq_20.0_Hz_ws_10   \n",
       "0                                           -3.406519e-02  \\\n",
       "1                                            1.018178e-03   \n",
       "2                                           -1.470459e-01   \n",
       "3                                            5.910165e-02   \n",
       "4                                            7.756041e-02   \n",
       "...                                                   ...   \n",
       "1900-01-01 00:27:16.700000                  -2.312702e-02   \n",
       "1900-01-01 00:25:19.700000                  -2.775558e-17   \n",
       "1900-01-01 00:24:57.200000                   2.742406e-03   \n",
       "1900-01-01 00:27:31.700000                   5.551115e-17   \n",
       "1900-01-01 00:25:58.700000                   8.616744e-02   \n",
       "\n",
       "                            Gamma_TP10_freq_30.0_Hz_ws_10   \n",
       "0                                           -1.800379e-02  \\\n",
       "1                                           -2.257550e-02   \n",
       "2                                           -7.400607e-02   \n",
       "3                                            5.320403e-02   \n",
       "4                                            8.382619e-02   \n",
       "...                                                   ...   \n",
       "1900-01-01 00:27:16.700000                  -2.271643e-02   \n",
       "1900-01-01 00:25:19.700000                  -1.387779e-17   \n",
       "1900-01-01 00:24:57.200000                  -3.178164e-02   \n",
       "1900-01-01 00:27:31.700000                   2.775558e-17   \n",
       "1900-01-01 00:25:58.700000                  -3.145519e-02   \n",
       "\n",
       "                            Gamma_TP10_freq_40.0_Hz_ws_10   \n",
       "0                                            9.280505e-03  \\\n",
       "1                                           -2.366062e-02   \n",
       "2                                           -5.530642e-02   \n",
       "3                                            5.021667e-02   \n",
       "4                                            7.957028e-02   \n",
       "...                                                   ...   \n",
       "1900-01-01 00:27:16.700000                  -2.233911e-02   \n",
       "1900-01-01 00:25:19.700000                  -2.775558e-17   \n",
       "1900-01-01 00:24:57.200000                  -1.113937e-02   \n",
       "1900-01-01 00:27:31.700000                   1.387779e-17   \n",
       "1900-01-01 00:25:58.700000                  -6.522804e-02   \n",
       "\n",
       "                            Gamma_TP10_freq_50.0_Hz_ws_10  class  \n",
       "0                                            6.223235e-04    0.0  \n",
       "1                                           -2.576942e-02    0.0  \n",
       "2                                           -9.821715e-02    0.0  \n",
       "3                                            4.955530e-02    0.0  \n",
       "4                                            7.309734e-02    0.0  \n",
       "...                                                   ...    ...  \n",
       "1900-01-01 00:27:16.700000                  -2.211485e-02    0.0  \n",
       "1900-01-01 00:25:19.700000                  -2.775558e-17    0.0  \n",
       "1900-01-01 00:24:57.200000                  -1.382244e-02    0.0  \n",
       "1900-01-01 00:27:31.700000                   1.734723e-17    0.0  \n",
       "1900-01-01 00:25:58.700000                  -5.188372e-02    0.0  \n",
       "\n",
       "[3132 rows x 585 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c72e464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "282"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.isnull().sum()\n",
    "# check_nan_in_df = train_X.isnull()\n",
    "# print (check_nan_in_df)\n",
    "train_X.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "469e2b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X.info"
   ]
  },
  {
   "cell_type": "raw",
   "id": "687ef49e",
   "metadata": {},
   "source": [
    "train_X = pd.DataFrame(train_X)\n",
    "train_X = train_X.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7dbc315f",
   "metadata": {},
   "source": [
    "train_X.isnull().sum()\n",
    "# check_nan_in_df = train_X.isnull()\n",
    "# print (check_nan_in_df)\n",
    "train_X.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f26a7db",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m class_train_y, class_test_y, class_train_prob_y, class_test_prob_y \u001b[39m=\u001b[39m random_forest(\n\u001b[0;32m      2\u001b[0m             train_X, train_y, test_X, gridsearch\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, print_model_details\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, save_model\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      3\u001b[0m performance_training_rf_final \u001b[39m=\u001b[39m \u001b[39meval\u001b[39m\u001b[39m.\u001b[39mf1(train_y, class_train_y)\n\u001b[0;32m      4\u001b[0m performance_test_rf_final \u001b[39m=\u001b[39m \u001b[39meval\u001b[39m\u001b[39m.\u001b[39mf1(test_y, class_test_y)\n",
      "Cell \u001b[1;32mIn[7], line 18\u001b[0m, in \u001b[0;36mrandom_forest\u001b[1;34m(train_X, train_y, test_X, n_estimators, min_samples_leaf, criterion, print_model_details, gridsearch, save_model)\u001b[0m\n\u001b[0;32m     14\u001b[0m     rf \u001b[39m=\u001b[39m RandomForestClassifier(n_estimators\u001b[39m=\u001b[39mn_estimators, min_samples_leaf\u001b[39m=\u001b[39mmin_samples_leaf, criterion\u001b[39m=\u001b[39mcriterion)\n\u001b[0;32m     16\u001b[0m \u001b[39m# Fit the model\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m rf\u001b[39m.\u001b[39;49mfit(train_X, train_y\u001b[39m.\u001b[39;49mcheck\u001b[39m.\u001b[39;49mravel())\n\u001b[0;32m     20\u001b[0m \u001b[39mif\u001b[39;00m gridsearch \u001b[39mand\u001b[39;00m print_model_details:\n\u001b[0;32m     21\u001b[0m     \u001b[39mprint\u001b[39m(rf\u001b[39m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32mc:\\Users\\DUC_AN\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\DUC_AN\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\DUC_AN\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\DUC_AN\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\DUC_AN\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mc:\\Users\\DUC_AN\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DUC_AN\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\DUC_AN\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\DUC_AN\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\DUC_AN\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\DUC_AN\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\DUC_AN\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\DUC_AN\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\DUC_AN\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:345\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[39mif\u001b[39;00m issparse(y):\n\u001b[0;32m    344\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 345\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    346\u001b[0m     X, y, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mDTYPE\n\u001b[0;32m    347\u001b[0m )\n\u001b[0;32m    348\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    349\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32mc:\\Users\\DUC_AN\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    583\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    585\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\DUC_AN\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[1;32m-> 1106\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1107\u001b[0m     X,\n\u001b[0;32m   1108\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m   1109\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m   1110\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1111\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1112\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1113\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m   1114\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m   1115\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m   1116\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m   1117\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m   1118\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1119\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[0;32m   1122\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\DUC_AN\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    918\u001b[0m         )\n\u001b[0;32m    920\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 921\u001b[0m         _assert_all_finite(\n\u001b[0;32m    922\u001b[0m             array,\n\u001b[0;32m    923\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    924\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    925\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    926\u001b[0m         )\n\u001b[0;32m    928\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mc:\\Users\\DUC_AN\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    145\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    148\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m     )\n\u001b[1;32m--> 161\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "class_train_y, class_test_y, class_train_prob_y, class_test_prob_y = random_forest(\n",
    "            train_X, train_y, test_X, gridsearch=True, print_model_details=True, save_model=True)\n",
    "performance_training_rf_final = eval.f1(train_y, class_train_y)\n",
    "performance_test_rf_final = eval.f1(test_y, class_test_y)\n",
    "confusionmatrix_rf_final = eval.confusion_matrix(test_y, class_test_y, ['check'])\n",
    "print(performance_test_rf_final) #test performance is reasonable!\n",
    "print(confusionmatrix_rf_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff25880d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343adf7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
